heat_template_version: 2015-04-30
description: Docker Hosts for Openstack
parameters:
  image:
    type: string
    description: Image used for servers
    default: docker-prebake-0.2
  key:
    type: string
    description: SSH key to connect to the servers
    default: drew_keypair
  docker_flavor:
    type: string
    description: flavor used by the Docker servers
    default: m1.medium
resources:
  docker_asg:
    type: OS::Heat::AutoScalingGroup
    properties:
      min_size: 2
      max_size: 3
      resource: 
        type: OS::Nova::Server
        properties:
          name: docker
          flavor: {get_param: docker_flavor}
          image: {get_param: image}
          key_name: {get_param: key}
          networks: [{network: {get_resource: docker_network} }]
          metadata: {"metering.stack": {get_param: "OS::stack_id"}}
          security_groups: 
            - {get_resource: docker_secgroup }
          user_data:
            str_replace:
              template: |
                #!/bin/bash -v
                /usr/bin/curl -ssL -o /tmp/install-rexray.sh https://dl.bintray.com/emccode/rexray/install
                chmod +x /tmp/install-rexray.sh
                /tmp/install-rexray.sh
                rm -f /etc/rexray/config.yml
                cat << EOF >> /etc/rexray/config.yml
                rexray:
                  storageDrivers:
                    - openstack
                  volume:
                    mount:
                      preempt: true
                openstack:
                  authUrl: http://172.24.4.1:35357/v2.0
                  username: admin
                  password: foopassword
                  tenantName: alt_demo
                  regionName: RegionOne
                EOF
                chgrp docker /etc/rexray/config.yml
                rexray start
              params:
                dummy: ""
  docker_secgroup:
     type: OS::Neutron::SecurityGroup
     properties:
      rules:
        - protocol: icmp
          remote_ip_prefix: 0.0.0.0/0
        - protocol: tcp
          remote_ip_prefix: 0.0.0.0/0
          port_range_min: 22
          port_range_max: 22
        - protocol: tcp
          remote_ip_prefix: 0.0.0.0/0
          port_range_min: 80
          port_range_max: 80
  docker_scaleup_policy:
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: {get_resource: docker_asg}
      cooldown: 60
      scaling_adjustment: 1
  docker_scaledown_policy:
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: {get_resource: docker_asg}
      cooldown: 60
      scaling_adjustment: -1
  docker_network:
    type: OS::Neutron::Net
    properties:
      name: docker_net
  docker_subnet:
    type: OS::Neutron::Subnet
    properties:
      network: {get_resource: docker_network}
      cidr: 192.168.23.0/24
      dns_nameservers: [ "8.8.8.8", "8.8.4.4" ]
      ip_version: 4
  docker_router:
     type: OS::Neutron::Router
     properties:
       external_gateway_info: { network: public }
  docker_router_interface:
     type: OS::Neutron::RouterInterface
     properties:
       router_id: { get_resource: docker_router }
       subnet: { get_resource: docker_subnet }
  monitor:
    type: OS::Neutron::HealthMonitor
    properties:
      type: TCP
      delay: 5
      max_retries: 5
      timeout: 5
outputs:
  scale_up_url:
    description: >
      This URL is the webhook to scale up the group.  You can invoke
      the scale-up operation by doing an HTTP POST to this URL; no
      body nor extra headers are needed.
    value: {get_attr: [docker_scaleup_policy, alarm_url]}
  scale_dn_url:
    description: >
      This URL is the webhook to scale down the group.  You can invoke
      the scale-down operation by doing an HTTP POST to this URL; no
      body nor extra headers are needed.
    value: {get_attr: [docker_scaledown_policy, alarm_url]}
  asg_size:
    description: >
      This is the current size of the auto scaling group.
    value: {get_attr: [docker_asg, current_size]}
  server_list:
    description: >
      This is a list of server names that are part of the group.
    value: {get_attr: [docker_asg, outputs_list, name]}
  networks:
    description: >
      This is a map of server resources and their networks.
    value: {get_attr: [docker_asg, outputs, networks]}
  server_ips:
    description: >
      This is a list of first ip addresses of the servers in the group
      for a specified network.
    value: {get_attr: [docker_asg, outputs_list, networks, {get_param: network}, 0]}
  ceilometer_query: 
    value:
      str_replace:
        template: >
          ceilometer statistics -m cpu_util
          -q metadata.user_metadata.stack=stackval -p 600 -a avg
        params:
          stackval: { get_param: "OS::stack_id" }
    description: >
      This is a Ceilometer query for statistics on the cpu_util meter
      Samples about OS::Nova::Server instances in this stack.  The -q
      parameter selects Samples according to the subject's metadata.
      When a VM's metadata includes an item of the form metering.X=Y,
      the corresponding Ceilometer resource has a metadata item of the
      form user_metadata.X=Y and samples about resources so tagged can
      be queried with a Ceilometer query term of the form
      metadata.user_metadata.X=Y.  In this case the nested stacks give
      their VMs metadata that is passed as a nested stack parameter,
      and this stack passes a metadata of the form metering.stack=Y,
      where Y is this stack's ID.
